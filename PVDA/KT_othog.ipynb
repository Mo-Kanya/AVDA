{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FADAnet.FADAloader import *\n",
    "from FADAnet.FADAmodule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 81  # total number of epoch\n",
    "n_epoch_pt = 0\n",
    "batch_size = 256\n",
    "batch_size_test = 512\n",
    "lr = 0.001\n",
    "gamma = 0.0005\n",
    "n_support = 7\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "np.random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "torch.cuda.manual_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "train_dataloader=mnist_dataloader(batch_size=batch_size,train=True)\n",
    "test_dataloader=mnist_dataloader(train=False)\n",
    "real_test_loader = svhn_dataloader(batch_size = batch_size_test, train=False)\n",
    "\n",
    "classifier=Classifier()\n",
    "encoder=Encoder()\n",
    "\n",
    "classifier.to(device)\n",
    "encoder.to(device)\n",
    "loss_fn1 = torch.nn.CrossEntropyLoss()\n",
    "loss_fn2 = torch.nn.CosineEmbeddingLoss()\n",
    "optimizer=torch.optim.Adam(list(encoder.parameters())+list(classifier.parameters()))\n",
    "\n",
    "X_t, Y_t = create_target_samples(n=n_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1: 1.6307697296142578    loss2: 28.64988899230957\n",
      "On source domain: Epoch 1/81  accuracy: 0.855 \n",
      "-------------------------------------------------\n",
      "On target domain: Epoch 1/81  accuracy: 0.23203125\n",
      "-------------------------------------------------\n",
      "loss1: 1.5232528448104858    loss2: 7.257229804992676\n",
      "loss1: 1.4714350700378418    loss2: 2.1498336791992188\n",
      "On source domain: Epoch 11/81  accuracy: 0.985 \n",
      "loss1: 1.4670677185058594    loss2: 1.4105409383773804\n",
      "loss1: 1.4917410612106323    loss2: 0.9906170964241028\n",
      "On source domain: Epoch 21/81  accuracy: 0.989 \n",
      "-------------------------------------------------\n",
      "On target domain: Epoch 21/81  accuracy: 0.2095703125\n",
      "-------------------------------------------------\n",
      "loss1: 1.4611505270004272    loss2: 0.5555048584938049\n",
      "loss1: 1.46116304397583    loss2: 0.534331202507019\n",
      "On source domain: Epoch 31/81  accuracy: 0.987 \n",
      "loss1: 1.4647431373596191    loss2: 0.41368842124938965\n",
      "loss1: 1.470369815826416    loss2: 0.3746226727962494\n",
      "On source domain: Epoch 41/81  accuracy: 0.987 \n",
      "-------------------------------------------------\n",
      "On target domain: Epoch 41/81  accuracy: 0.2408203125\n",
      "-------------------------------------------------\n",
      "loss1: 1.4611574411392212    loss2: 0.28290536999702454\n",
      "loss1: 1.4611505270004272    loss2: 0.20121832191944122\n",
      "On source domain: Epoch 51/81  accuracy: 0.991 \n",
      "loss1: 1.4624156951904297    loss2: 0.20997118949890137\n",
      "loss1: 1.4819837808609009    loss2: 0.1868722289800644\n",
      "On source domain: Epoch 61/81  accuracy: 0.987 \n",
      "-------------------------------------------------\n",
      "On target domain: Epoch 61/81  accuracy: 0.2724609375\n",
      "-------------------------------------------------\n",
      "loss1: 1.4908925294876099    loss2: 0.2018318623304367\n",
      "loss1: 1.471567153930664    loss2: 0.14606919884681702\n",
      "On source domain: Epoch 71/81  accuracy: 0.989 \n",
      "loss1: 1.4611505270004272    loss2: 0.12152400612831116\n",
      "loss1: 1.4819837808609009    loss2: 0.18294262886047363\n",
      "On source domain: Epoch 81/81  accuracy: 0.990 \n",
      "-------------------------------------------------\n",
      "On target domain: Epoch 81/81  accuracy: 0.2630859375\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# for epoch in tqdm(range(n_epoch)):\n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    for data,labels in train_dataloader:\n",
    "        data=data.to(device)\n",
    "        labels=labels.to(device)\n",
    "        X_t = X_t.to(device)\n",
    "        Y_t = Y_t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        map_s = encoder(data)\n",
    "        y_pred=classifier(map_s)\n",
    "        loss1=loss_fn1(y_pred,labels)\n",
    "        map_t = encoder(X_t)\n",
    "        \n",
    "        loss2 = 0\n",
    "        means_s = []\n",
    "        # means_t = []\n",
    "        for num in range(10):\n",
    "#             subset = map_t[Y_t == num]\n",
    "#             means_t.append(torch.mean(subset, dim = 0))\n",
    "            subset = map_s[labels == num]\n",
    "            means_s.append(torch.mean(subset, dim = 0))\n",
    "        for ctr in range(10*n_support):\n",
    "            num = Y_t[ctr]\n",
    "            tmp = map_t[ctr] - means_s[num]\n",
    "            dd = torch.stack([tmp]*9)\n",
    "            tmp = [(means_s[num] - means_s[i]) for i in range(10) if i != num]\n",
    "            Cplane = torch.stack(tmp)\n",
    "            loss2 += loss_fn2(-dd, Cplane, torch.FloatTensor([-1]*9).to(device))\n",
    "            loss2 += loss_fn2(dd, Cplane, torch.FloatTensor([-1]*9).to(device))\n",
    "        loss = loss1 + gamma*loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%5 == 0: print(\"loss1:\", loss1.item(), \"   loss2:\", loss2.item())\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "        acc=0\n",
    "        for data,labels in test_dataloader:\n",
    "            data=data.to(device)\n",
    "            labels=labels.to(device)\n",
    "            y_test_pred=classifier(encoder(data))\n",
    "            acc+=(torch.max(y_test_pred,1)[1]==labels).float().mean().item()\n",
    "        accuracy=round(acc / float(len(test_dataloader)), 3)\n",
    "        print(\"On source domain: Epoch %d/%d  accuracy: %.3f \"%(epoch+1,n_epoch,accuracy))\n",
    "    \n",
    "    if epoch%20 == 0:\n",
    "        mapset_f = []\n",
    "        labelset_f = []\n",
    "        # count_map = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "        for data, labels in train_dataloader:\n",
    "            data = data.to(device)\n",
    "            labels=labels.to(device)\n",
    "            map_f = encoder(data)\n",
    "            mapset_f.append(map_f)\n",
    "            labelset_f.append(labels)\n",
    "        map_f = torch.cat(mapset_f[:-1])\n",
    "        label_f = torch.cat(labelset_f[:-1])\n",
    "\n",
    "        means_f = []\n",
    "        for num in range(10):\n",
    "            subset = map_f[label_f == num]\n",
    "            means_f.append(torch.mean(subset, dim = 0))\n",
    "        nume = 0\n",
    "        deno = 0\n",
    "        for data, labels in real_test_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            tmp = encoder(data)\n",
    "\n",
    "            map_ff = encoder(data)\n",
    "            for ctr in range(batch_size_test):\n",
    "#                 num = labels[ctr]\n",
    "#                 tmp = map_ff[ctr] - means_f[num]\n",
    "#                 dd_f = torch.stack([tmp]*9)\n",
    "#                 tmp = [(means_f[num] - means_f[i]) for i in range(10) if i != num]\n",
    "#                 Cplane_f = torch.stack(tmp)\n",
    "#                 loss_real = loss_fn2(-dd_f, Cplane_f, torch.FloatTensor([-1]*9).to(device)) + loss_fn2(dd_f, Cplane_f, torch.FloatTensor([-1]*9).to(device))\n",
    "\n",
    "                others = []\n",
    "                for j in range(10):\n",
    "                    num = j\n",
    "                    tmp = map_ff[ctr] - means_f[num]\n",
    "                    dd_f = torch.stack([tmp]*9)\n",
    "                    tmp = [(means_f[num] - means_f[i]) for i in range(10) if i != num]\n",
    "                    Cplane_f = torch.stack(tmp)\n",
    "                    loss_f = loss_fn2(-dd_f, Cplane_f, torch.FloatTensor([-1]*9).to(device)) + loss_fn2(dd_f, Cplane_f, torch.FloatTensor([-1]*9).to(device))\n",
    "                    others.append(loss_f.item())\n",
    "                # print(min(others))\n",
    "                if np.argmin(others) == labels[ctr]: \n",
    "                    nume+=1\n",
    "                    # count_map[labels[ctr].item()] += 1\n",
    "            deno += batch_size_test\n",
    "            if deno > 5100: break\n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(\"On target domain: Epoch %d/%d  accuracy:\"%(epoch+1,n_epoch), nume / deno)\n",
    "        # print(count_map)\n",
    "        print(\"-------------------------------------------------\")\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
